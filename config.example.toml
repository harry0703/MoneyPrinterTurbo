[app]
    # Pexels API Key
    # Register at https://www.pexels.com/api/ to get your API key.
    # You can use multiple keys to avoid rate limits.
    # For example: pexels_api_keys = ["123adsf4567adf89","abd1321cd13efgfdfhi"]
    # 特别注意格式，Key 用英文双引号括起来，多个Key用逗号隔开
    pexels_api_keys = []

    # 如果你没有 OPENAI API Key，可以使用 g4f 代替，或者使用国内的 Moonshot API
    # If you don't have an OPENAI API Key, you can use g4f instead

    # 支持的提供商 (Supported providers):
    #   openai
    #   moonshot (月之暗面)
    #   oneapi
    #   g4f
    #   azure
    #   qwen (通义千问)
    #   gemini
    llm_provider="openai"

    ########## OpenAI API Key
    # Get your API key at https://platform.openai.com/api-keys
    openai_api_key = ""
    # No need to set it unless you want to use your own proxy
    openai_base_url = ""
    # Check your available models at https://platform.openai.com/account/limits
    openai_model_name = "gpt-4-turbo-preview"

    ########## Moonshot API Key
    # Visit https://platform.moonshot.cn/console/api-keys to get your API key.
    moonshot_api_key=""
    moonshot_base_url = "https://api.moonshot.cn/v1"
    moonshot_model_name = "moonshot-v1-8k"

    ########## OneAPI API Key
    # Visit https://github.com/songquanpeng/one-api to get your API key
    oneapi_api_key=""
    oneapi_base_url=""
    oneapi_model_name=""

    ########## G4F
    # Visit https://github.com/xtekky/gpt4free to get more details
    # Supported model list: https://github.com/xtekky/gpt4free/blob/main/g4f/models.py
    g4f_model_name = "gpt-3.5-turbo-16k-0613"

    ########## Azure API Key
    # Visit https://learn.microsoft.com/zh-cn/azure/ai-services/openai/ to get more details
    # API documentation: https://learn.microsoft.com/zh-cn/azure/ai-services/openai/reference
    azure_api_key = ""
    azure_base_url=""
    azure_model_name="gpt-35-turbo" # replace with your model deployment name
    azure_api_version = "2024-02-15-preview"

    ########## Gemini API Key
    gemini_api_key=""
    gemini_model_name = "gemini-1.0-pro"

    ########## Qwen API Key
    # Visit https://dashscope.console.aliyun.com/apiKey to get your API key
    # Visit below links to get more details
    # https://tongyi.aliyun.com/qianwen/
    # https://help.aliyun.com/zh/dashscope/developer-reference/model-introduction
    qwen_api_key = ""
    qwen_model_name = "qwen-max" 


    # Subtitle Provider, "edge" or "whisper"
    # If empty, the subtitle will not be generated
    subtitle_provider = "edge"

    #
    # ImageMagick
    #
    # Once you have installed it, ImageMagick will be automatically detected, except on Windows!
    # On Windows, for example "C:\Program Files (x86)\ImageMagick-7.1.1-Q16-HDRI\magick.exe"
    # Download from https://imagemagick.org/archive/binaries/ImageMagick-7.1.1-29-Q16-x64-static.exe

    # imagemagick_path = "C:\\Program Files (x86)\\ImageMagick-7.1.1-Q16\\magick.exe"


    #
    # FFMPEG
    #
    # 通常情况下，ffmpeg 会被自动下载，并且会被自动检测到。
    # 但是如果你的环境有问题，无法自动下载，可能会遇到如下错误：
    #   RuntimeError: No ffmpeg exe could be found.
    #   Install ffmpeg on your system, or set the IMAGEIO_FFMPEG_EXE environment variable.
    # 此时你可以手动下载 ffmpeg 并设置 ffmpeg_path，下载地址：https://www.gyan.dev/ffmpeg/builds/

    # Under normal circumstances, ffmpeg is downloaded automatically and detected automatically.
    # However, if there is an issue with your environment that prevents automatic downloading, you might encounter the following error:
    #   RuntimeError: No ffmpeg exe could be found.
    #   Install ffmpeg on your system, or set the IMAGEIO_FFMPEG_EXE environment variable.
    # In such cases, you can manually download ffmpeg and set the ffmpeg_path, download link: https://www.gyan.dev/ffmpeg/builds/

    # ffmpeg_path = "C:\\Users\\harry\\Downloads\\ffmpeg.exe"
    #########################################################################################

[whisper]
    # Only effective when subtitle_provider is "whisper"

    # Run on GPU with FP16
    # model = WhisperModel(model_size, device="cuda", compute_type="float16")

    # Run on GPU with INT8
    # model = WhisperModel(model_size, device="cuda", compute_type="int8_float16")

    # Run on CPU with INT8
    # model = WhisperModel(model_size, device="cpu", compute_type="int8")

    # recommended model_size: "large-v3"
    model_size="large-v3"
    # if you want to use GPU, set device="cuda"
    device="CPU"
    compute_type="int8"

[pexels]
    video_concat_mode="sequential" # "random" or "sequential"
    [pexels.proxies]
        ### Use a proxy to access the Pexels API
        ### Format: "http://<username>:<password>@<proxy>:<port>"
        ### Example: "http://user:pass@proxy:1234"
        ### Doc: https://requests.readthedocs.io/en/latest/user/advanced/#proxies
        # http = "http://10.10.1.10:3128"
        # https = "http://10.10.1.10:1080"